ğŸ­ MOTIVATING AI
ğŸ‘¥ Team Name: GEMS



ğŸ‘©â€ğŸ’» Team Members

Nandana Kailas â€“ Saintgits College of Engineering

Sharon Elsa Binu â€“ Saintgits College of Engineering

ğŸ”— Hosted Project Link:
https://github.com/Nandana-kailas/MotivatingAI

ğŸ“Œ Project Description

Motivating AI is an AI-powered real-time emotion detection system that analyzes facial expressions using a webcam and automatically plays emotion-mapped Malayalam movie dialogues ğŸ¬.

The system uses Computer Vision and Deep Learning to detect user emotions and respond with humorous or motivational dialogue audio to improve mood and reduce stress.

â— Problem Statement

In modern office environments, employees often experience high levels of stress, work pressure, and mental fatigue due to tight deadlines, multitasking, and continuous screen exposure.

Although organizations implement stress-management strategies, there is a lack of real-time, emotion-aware systems that can instantly respond to an individual's emotional state during work hours.

ğŸ’¡ Proposed Solution

To address this gap, we developed a lightweight AI-based application that:

Detects facial emotions in real-time using a webcam

Classifies emotional states such as Happy, Sad, or Lazy

Plays appropriate Malayalam movie dialogues to lighten the mood

This project provides quick emotional relief using minimal computational resources while creating a positive and interactive workplace experience.

ğŸš€ Features

ğŸ¥ Real-time webcam face detection

ğŸ§  Emotion recognition using Deep Learning

ğŸ”Š Automatic audio playback based on detected emotion

ğŸ“Š 3-second emotion averaging for stable detection

ğŸ’¤ Detects "Lazy" when no face is properly detected

ğŸ’» Lightweight desktop execution

ğŸ› ï¸ Tech Stack

Python 3.10+

OpenCV â€“ Webcam capture & video processing

FER â€“ Facial emotion recognition

MTCNN â€“ Face detection backend

Pygame â€“ Audio playback

NumPy

ğŸ“‚ Project Structure
MotivatingAI/
â”‚
â”œâ”€â”€ audio/
â”‚   â”œâ”€â”€ happy/
â”‚   â”œâ”€â”€ sad/
â”‚   â””â”€â”€ lazy/
â”‚
â”œâ”€â”€ emotion_bot.py
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

âš™ï¸ Installation
1ï¸âƒ£ Clone the Repository
git clone https://github.com/Nandana-kailas/MotivatingAI.git

cd MotivatingAI

2ï¸âƒ£ Create Virtual Environment (Recommended)

python -m venv venv


Activate (Windows):

venv\Scripts\activate

3ï¸âƒ£ Install Dependencies

pip install -r requirements.txt


If requirements.txt is missing:

pip install opencv-python fer mtcnn pygame numpy

â–¶ï¸ Run the Project

python app.py


Press Q to quit the application.

ğŸ§  How It Works

Webcam captures live video feed

Face is detected using MTCNN

Emotions are analyzed using FER

Emotion scores are averaged over 3 seconds

Final emotion is classified

Emotion Classification Logic
Emotion	Condition
Happy	avg_happy > 0.6
Sad	avg_sad > 0.4 OR avg_neutral > 0.5
Lazy	No face detected

After classification, a corresponding Malayalam movie dialogue is played from the audio/ folder.

ğŸ“· Example Output
Sad: 0.12 | Happy: 0.78 | Neutral: 0.10  
ğŸ”¥ Final Emotion: HAPPY  
ğŸ”Š Playing: audio/happy/dialogue1.mp3


Demo Output & Results

Screenshot1:   https://github.com/Nandana-kailas/MotivatingAI/blob/main/Screenshot%202026-02-15%20093715.png

Screenshot2:   https://github.com/Nandana-kailas/MotivatingAI/blob/main/Screenshot%202026-02-15%20093728.png

Screenshot3:   https://github.com/Nandana-kailas/MotivatingAI/blob/main/Screenshot%202026-02-15%20093753.png

Screenshot4:   https://github.com/Nandana-kailas/MotivatingAI/blob/main/Screenshot%202026-02-15%20093815.png

ğŸ”® Future Improvements

Add more emotions (Angry, Disgust, Surprise)

Improve detection accuracy

Add graphical user interface (GUI)

Expand Malayalam movie dialogue database ğŸ¬

Convert into desktop executable (.exe)



ğŸ‘©â€ğŸ’» Team Contributions

ğŸ”¹ Sharon Elsa Binu

Core emotion detection logic

Audio integration

Deployment setup

Debugging and testing

ğŸ”¹ Nandana Kailas

Audio selection and mapping

GitHub management

Documentation preparation

ğŸ“„ License

This project is open-source and available under the MIT License.
